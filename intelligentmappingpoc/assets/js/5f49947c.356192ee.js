"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[1658],{28453:(e,n,s)=>{s.d(n,{R:()=>i,x:()=>o});var r=s(96540);const a={},t=r.createContext(a);function i(e){const n=r.useContext(t);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:i(e.components),r.createElement(t.Provider,{value:n},e.children)}},52471:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>i,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"csv-parser/examples","title":"Examples","description":"Practical examples for using the CSV Parser microservice.","source":"@site/docs/csv-parser/examples.md","sourceDirName":"csv-parser","slug":"/csv-parser/examples","permalink":"/fintech-mapping-features/intelligentmappingpoc/docs/csv-parser/examples","draft":false,"unlisted":false,"editUrl":"https://github.com/Ejyke90/fintech-mapping-features/tree/main/docs/docs/csv-parser/examples.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3}}');var a=s(74848),t=s(28453);const i={sidebar_position:3},o="Examples",l={},c=[{value:"Basic Usage",id:"basic-usage",level:2},{value:"Parse a Simple CSV File",id:"parse-a-simple-csv-file",level:3},{value:"Validation",id:"validation",level:2},{value:"Validate CSV Structure",id:"validate-csv-structure",level:3},{value:"Schema Extraction",id:"schema-extraction",level:2},{value:"Get CSV Schema Information",id:"get-csv-schema-information",level:3},{value:"Data Transformation",id:"data-transformation",level:2},{value:"Clean and Transform CSV Data",id:"clean-and-transform-csv-data",level:3},{value:"Advanced Usage",id:"advanced-usage",level:2},{value:"Process Large Files with Chunking",id:"process-large-files-with-chunking",level:3},{value:"Handle Different Encodings and Delimiters",id:"handle-different-encodings-and-delimiters",level:3},{value:"Integration Examples",id:"integration-examples",level:2},{value:"Prepare CSV for XML Transformation",id:"prepare-csv-for-xml-transformation",level:3},{value:"Prepare CSV for Mapping Generation",id:"prepare-csv-for-mapping-generation",level:3},{value:"Error Handling",id:"error-handling",level:2},{value:"Robust Error Handling",id:"robust-error-handling",level:3},{value:"Batch Processing",id:"batch-processing",level:2},{value:"Process Multiple CSV Files",id:"process-multiple-csv-files",level:3},{value:"JavaScript/TypeScript Examples",id:"javascripttypescript-examples",level:2},{value:"Using Fetch API",id:"using-fetch-api",level:3},{value:"Next Steps",id:"next-steps",level:2}];function p(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"examples",children:"Examples"})}),"\n",(0,a.jsx)(n.p,{children:"Practical examples for using the CSV Parser microservice."}),"\n",(0,a.jsx)(n.h2,{id:"basic-usage",children:"Basic Usage"}),"\n",(0,a.jsx)(n.h3,{id:"parse-a-simple-csv-file",children:"Parse a Simple CSV File"}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Sample CSV:"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-csv",children:"name,age,email,department\nJohn Doe,30,john@example.com,Engineering\nJane Smith,25,jane@example.com,Marketing\nBob Johnson,35,bob@example.com,Sales\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Python Example:"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import requests\n\n# Parse the CSV file\nwith open('employees.csv', 'rb') as f:\n    response = requests.post(\n        'http://localhost:8000/api/csv/parse',\n        files={'file': f}\n    )\n\nresult = response.json()\nprint(f\"Status: {result['status']}\")\nprint(f\"Rows: {result['row_count']}\")\nprint(f\"Columns: {result['columns']}\")\n\n# Access data\nfor row in result['data']:\n    print(f\"{row['name']} - {row['department']}\")\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"cURL Example:"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"curl -X POST http://localhost:8000/api/csv/parse \\\n  -F \"file=@employees.csv\" \\\n  | jq '.'\n"})}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"validation",children:"Validation"}),"\n",(0,a.jsx)(n.h3,{id:"validate-csv-structure",children:"Validate CSV Structure"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import requests\n\nwith open('data.csv', 'rb') as f:\n    response = requests.post(\n        'http://localhost:8000/api/csv/validate',\n        files={'file': f}\n    )\n\nvalidation = response.json()\n\nif validation['is_valid']:\n    print(\"\u2713 CSV is valid\")\n    print(f\"Rows: {validation['row_count']}\")\n    print(f\"Columns: {validation['column_count']}\")\nelse:\n    print(\"\u2717 CSV has errors:\")\n    for error in validation['errors']:\n        print(f\"  - {error}\")\n\n# Check for missing values\nif validation['missing_values']:\n    print(\"\\nMissing values found:\")\n    for col, count in validation['missing_values'].items():\n        print(f\"  {col}: {count} missing\")\n"})}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"schema-extraction",children:"Schema Extraction"}),"\n",(0,a.jsx)(n.h3,{id:"get-csv-schema-information",children:"Get CSV Schema Information"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import requests\n\nwith open('financial_data.csv', 'rb') as f:\n    response = requests.post(\n        'http://localhost:8000/api/csv/schema',\n        files={'file': f}\n    )\n\nschema = response.json()\n\nprint(f\"File size: {schema['estimated_size_mb']:.2f} MB\")\nprint(f\"Total rows: {schema['row_count']}\")\nprint(\"\\nColumns:\")\n\nfor col in schema['columns']:\n    print(f\"\\n  {col['name']}:\")\n    print(f\"    Type: {col['dtype']}\")\n    print(f\"    Nullable: {col['nullable']}\")\n    print(f\"    Unique values: {col['unique_count']}\")\n    print(f\"    Sample: {col['sample_values']}\")\n    \n    if 'stats' in col:\n        print(f\"    Min: {col['stats']['min']}\")\n        print(f\"    Max: {col['stats']['max']}\")\n        print(f\"    Mean: {col['stats']['mean']}\")\n"})}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"data-transformation",children:"Data Transformation"}),"\n",(0,a.jsx)(n.h3,{id:"clean-and-transform-csv-data",children:"Clean and Transform CSV Data"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import requests\n\n# Transform with cleaning options\nwith open('messy_data.csv', 'rb') as f:\n    response = requests.post(\n        'http://localhost:8000/api/csv/transform',\n        files={'file': f},\n        params={\n            'remove_empty_rows': True,\n            'remove_duplicates': True,\n            'trim_whitespace': True,\n            'lowercase_columns': True\n        }\n    )\n\nresult = response.json()\nprint(f\"Original rows: {result['original_row_count']}\")\nprint(f\"Cleaned rows: {result['cleaned_row_count']}\")\nprint(f\"Removed: {result['original_row_count'] - result['cleaned_row_count']} rows\")\n\n# Save cleaned data\nimport json\nwith open('cleaned_data.json', 'w') as f:\n    json.dump(result['data'], f, indent=2)\n"})}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"advanced-usage",children:"Advanced Usage"}),"\n",(0,a.jsx)(n.h3,{id:"process-large-files-with-chunking",children:"Process Large Files with Chunking"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import requests\n\n# For files larger than 10MB, use chunking\nwith open('large_dataset.csv', 'rb') as f:\n    response = requests.post(\n        'http://localhost:8000/api/csv/parse',\n        files={'file': f},\n        params={'chunk_size': 5000}  # Process 5000 rows at a time\n    )\n\nresult = response.json()\nprint(f\"Processed {result['row_count']} rows\")\n"})}),"\n",(0,a.jsx)(n.h3,{id:"handle-different-encodings-and-delimiters",children:"Handle Different Encodings and Delimiters"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import requests\n\n# CSV with semicolon delimiter and ISO-8859-1 encoding\nwith open('european_data.csv', 'rb') as f:\n    response = requests.post(\n        'http://localhost:8000/api/csv/parse',\n        files={'file': f},\n        params={\n            'auto_detect': True,  # Let the parser detect encoding and delimiter\n        }\n    )\n\n# Or specify manually\nwith open('european_data.csv', 'rb') as f:\n    response = requests.post(\n        'http://localhost:8000/api/csv/parse',\n        files={'file': f},\n        params={\n            'auto_detect': False,\n            'encoding': 'iso-8859-1',\n            'delimiter': ';'\n        }\n    )\n"})}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"integration-examples",children:"Integration Examples"}),"\n",(0,a.jsx)(n.h3,{id:"prepare-csv-for-xml-transformation",children:"Prepare CSV for XML Transformation"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import requests\n\n# Prepare CSV data for XML transformation\nwith open('payment_instructions.csv', 'rb') as f:\n    response = requests.post(\n        'http://localhost:8000/api/csv/prepare-for-xml',\n        files={'file': f}\n    )\n\nresult = response.json()\n\nif result['xml_ready']:\n    print(\"\u2713 Data ready for XML transformation\")\n    print(f\"Schema: {result['schema']}\")\n    \n    # Use the data with XML Sanitizer\n    xml_data = result['data']\n    # ... transform to XML and send to XML Sanitizer\n"})}),"\n",(0,a.jsx)(n.h3,{id:"prepare-csv-for-mapping-generation",children:"Prepare CSV for Mapping Generation"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import requests\n\n# Prepare CSV schema for intelligent mapping\nwith open('source_data.csv', 'rb') as f:\n    response = requests.post(\n        'http://localhost:8000/api/csv/prepare-for-mapping',\n        files={'file': f},\n        params={'target_format': 'ISO20022_pain.001.001.09'}\n    )\n\nresult = response.json()\n\nif result['mapping_ready']:\n    print(\"\u2713 Schema ready for mapping generation\")\n    print(f\"Source schema: {result['source_schema']}\")\n    print(f\"Sample data: {result['sample_data'][:3]}\")\n    \n    # Send to Mapping Generator\n    # mapping_response = requests.post(\n    #     'http://localhost:8081/generate-mapping',\n    #     json=result\n    # )\n"})}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"error-handling",children:"Error Handling"}),"\n",(0,a.jsx)(n.h3,{id:"robust-error-handling",children:"Robust Error Handling"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import requests\nfrom requests.exceptions import RequestException\n\ndef parse_csv_safely(file_path):\n    try:\n        with open(file_path, 'rb') as f:\n            response = requests.post(\n                'http://localhost:8000/api/csv/parse',\n                files={'file': f},\n                timeout=30\n            )\n        \n        response.raise_for_status()\n        result = response.json()\n        \n        if result['status'] == 'success':\n            return result['data']\n        else:\n            print(f\"Error: {result.get('message')}\")\n            return None\n            \n    except FileNotFoundError:\n        print(f\"File not found: {file_path}\")\n        return None\n    \n    except RequestException as e:\n        print(f\"Request failed: {e}\")\n        return None\n    \n    except ValueError as e:\n        print(f\"Invalid JSON response: {e}\")\n        return None\n\n# Usage\ndata = parse_csv_safely('mydata.csv')\nif data:\n    print(f\"Successfully parsed {len(data)} rows\")\n"})}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"batch-processing",children:"Batch Processing"}),"\n",(0,a.jsx)(n.h3,{id:"process-multiple-csv-files",children:"Process Multiple CSV Files"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import requests\nimport os\nfrom pathlib import Path\n\ndef process_csv_directory(directory_path):\n    results = []\n    \n    for csv_file in Path(directory_path).glob('*.csv'):\n        print(f\"Processing {csv_file.name}...\")\n        \n        try:\n            with open(csv_file, 'rb') as f:\n                response = requests.post(\n                    'http://localhost:8000/api/csv/parse',\n                    files={'file': f}\n                )\n            \n            if response.status_code == 200:\n                result = response.json()\n                results.append({\n                    'filename': csv_file.name,\n                    'row_count': result['row_count'],\n                    'column_count': result['column_count'],\n                    'status': 'success'\n                })\n            else:\n                results.append({\n                    'filename': csv_file.name,\n                    'status': 'error',\n                    'error': response.text\n                })\n        \n        except Exception as e:\n            results.append({\n                'filename': csv_file.name,\n                'status': 'error',\n                'error': str(e)\n            })\n    \n    return results\n\n# Process all CSVs in a directory\nresults = process_csv_directory('./data/')\n\n# Print summary\nprint(\"\\nProcessing Summary:\")\nprint(f\"Total files: {len(results)}\")\nprint(f\"Successful: {sum(1 for r in results if r['status'] == 'success')}\")\nprint(f\"Failed: {sum(1 for r in results if r['status'] == 'error')}\")\n"})}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"javascripttypescript-examples",children:"JavaScript/TypeScript Examples"}),"\n",(0,a.jsx)(n.h3,{id:"using-fetch-api",children:"Using Fetch API"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"async function parseCSV(file: File): Promise<any> {\n  const formData = new FormData();\n  formData.append('file', file);\n\n  try {\n    const response = await fetch('http://localhost:8000/api/csv/parse', {\n      method: 'POST',\n      body: formData\n    });\n\n    if (!response.ok) {\n      throw new Error(`HTTP error! status: ${response.status}`);\n    }\n\n    const result = await response.json();\n    console.log(`Parsed ${result.row_count} rows`);\n    return result.data;\n    \n  } catch (error) {\n    console.error('Error parsing CSV:', error);\n    throw error;\n  }\n}\n\n// Usage in React\nfunction CSVUploader() {\n  const handleFileUpload = async (event: React.ChangeEvent<HTMLInputElement>) => {\n    const file = event.target.files?.[0];\n    if (!file) return;\n\n    try {\n      const data = await parseCSV(file);\n      console.log('CSV data:', data);\n    } catch (error) {\n      alert('Failed to parse CSV');\n    }\n  };\n\n  return <input type=\"file\" accept=\".csv\" onChange={handleFileUpload} />;\n}\n"})}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Review the ",(0,a.jsx)(n.a,{href:"/fintech-mapping-features/intelligentmappingpoc/docs/csv-parser/api-reference",children:"API Reference"})," for complete endpoint documentation"]}),"\n",(0,a.jsxs)(n.li,{children:["Check the ",(0,a.jsx)(n.a,{href:"/fintech-mapping-features/intelligentmappingpoc/docs/guides/integration-overview",children:"Integration Guide"})," for service orchestration patterns"]}),"\n",(0,a.jsx)(n.li,{children:"Explore the API Gateway documentation (see repository root)"}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(p,{...e})}):p(e)}}}]);