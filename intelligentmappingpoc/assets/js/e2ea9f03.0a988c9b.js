"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[8782],{8925:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>a,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"csv-parser/integration","title":"Integration Guide","description":"Learn how to integrate the CSV Parser with other microservices in the Fintech Mapping Features ecosystem.","source":"@site/docs/csv-parser/integration.md","sourceDirName":"csv-parser","slug":"/csv-parser/integration","permalink":"/fintech-mapping-features/intelligentmappingpoc/docs/csv-parser/integration","draft":false,"unlisted":false,"editUrl":"https://github.com/Ejyke90/fintech-mapping-features/tree/main/docs/docs/csv-parser/integration.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4}}');var s=r(74848),i=r(28453);const a={sidebar_position:4},o="Integration Guide",l={},c=[{value:"Integration Architecture",id:"integration-architecture",level:2},{value:"Direct Integration Patterns",id:"direct-integration-patterns",level:2},{value:"1. CSV Parser \u2192 XML Sanitizer",id:"1-csv-parser--xml-sanitizer",level:3},{value:"2. CSV Parser \u2192 Mapping Generator",id:"2-csv-parser--mapping-generator",level:3},{value:"Via API Gateway (Recommended)",id:"via-api-gateway-recommended",level:2},{value:"Full Transformation Pipeline",id:"full-transformation-pipeline",level:3},{value:"CSV to XML Only",id:"csv-to-xml-only",level:3},{value:"CSV to Mapping Only",id:"csv-to-mapping-only",level:3},{value:"Service-to-Service Communication",id:"service-to-service-communication",level:2},{value:"Async Integration with Message Queue",id:"async-integration-with-message-queue",level:3},{value:"Docker Integration",id:"docker-integration",level:2},{value:"Docker Compose Network",id:"docker-compose-network",level:3},{value:"Error Handling &amp; Retry Logic",id:"error-handling--retry-logic",level:2},{value:"Resilient Integration",id:"resilient-integration",level:3},{value:"Monitoring &amp; Observability",id:"monitoring--observability",level:2},{value:"Request Tracking",id:"request-tracking",level:3},{value:"Security Considerations",id:"security-considerations",level:2},{value:"API Authentication",id:"api-authentication",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Parallel Processing",id:"parallel-processing",level:3},{value:"Next Steps",id:"next-steps",level:2}];function p(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"integration-guide",children:"Integration Guide"})}),"\n",(0,s.jsx)(n.p,{children:"Learn how to integrate the CSV Parser with other microservices in the Fintech Mapping Features ecosystem."}),"\n",(0,s.jsx)(n.h2,{id:"integration-architecture",children:"Integration Architecture"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"CSV Parser (Port 8000)\n        \u2193\n    \u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2510\n    \u2193       \u2193\nXML         Mapping\nSanitizer   Generator\nPort 8080   Port 8081\n"})}),"\n",(0,s.jsx)(n.h2,{id:"direct-integration-patterns",children:"Direct Integration Patterns"}),"\n",(0,s.jsx)(n.h3,{id:"1-csv-parser--xml-sanitizer",children:"1. CSV Parser \u2192 XML Sanitizer"}),"\n",(0,s.jsx)(n.p,{children:"Transform CSV data into ISO 20022 XML format."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Workflow:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"1. Upload CSV to CSV Parser\n2. Parse and extract data\n3. Transform JSON to XML\n4. Send XML to XML Sanitizer\n5. Receive cleaned XML\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Example:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import requests\nimport xml.etree.ElementTree as ET\n\ndef csv_to_sanitized_xml(csv_file_path):\n    # Step 1: Parse CSV\n    with open(csv_file_path, 'rb') as f:\n        parse_response = requests.post(\n            'http://localhost:8000/api/csv/prepare-for-xml',\n            files={'file': f}\n        )\n    \n    csv_data = parse_response.json()\n    \n    if not csv_data['xml_ready']:\n        raise Exception(\"CSV not ready for XML transformation\")\n    \n    # Step 2: Transform to XML (simple example)\n    root = ET.Element('Document')\n    for row in csv_data['data']:\n        record = ET.SubElement(root, 'Record')\n        for key, value in row.items():\n            field = ET.SubElement(record, key)\n            field.text = str(value)\n    \n    xml_string = ET.tostring(root, encoding='unicode')\n    \n    # Step 3: Sanitize XML\n    sanitize_response = requests.post(\n        'http://localhost:8080/sanitize-chars',\n        data=xml_string,\n        headers={'Content-Type': 'application/xml'}\n    )\n    \n    return sanitize_response.text\n\n# Usage\ncleaned_xml = csv_to_sanitized_xml('payment_data.csv')\nprint(cleaned_xml)\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"2-csv-parser--mapping-generator",children:"2. CSV Parser \u2192 Mapping Generator"}),"\n",(0,s.jsx)(n.p,{children:"Generate intelligent field mappings from CSV schema."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Workflow:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"1. Upload CSV to CSV Parser\n2. Extract schema and sample data\n3. Send to Mapping Generator\n4. Receive field mappings\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Example:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import requests\n\ndef generate_mappings_from_csv(csv_file_path, target_format='ISO20022_pain.001.001.09'):\n    # Step 1: Prepare CSV for mapping\n    with open(csv_file_path, 'rb') as f:\n        prepare_response = requests.post(\n            'http://localhost:8000/api/csv/prepare-for-mapping',\n            files={'file': f},\n            params={'target_format': target_format}\n        )\n    \n    csv_schema = prepare_response.json()\n    \n    if not csv_schema['mapping_ready']:\n        raise Exception(\"CSV not ready for mapping\")\n    \n    # Step 2: Generate mappings\n    mapping_request = {\n        'sourceSchema': csv_schema['source_schema'],\n        'targetFormat': target_format,\n        'sampleData': csv_schema['sample_data']\n    }\n    \n    mapping_response = requests.post(\n        'http://localhost:8081/generate-mapping',\n        json=mapping_request\n    )\n    \n    mappings = mapping_response.json()\n    \n    # Display mappings\n    print(f\"Generated {len(mappings)} mappings:\")\n    for mapping in mappings:\n        print(f\"  {mapping['source_field']} \u2192 {mapping['target_field']}\")\n        print(f\"    Confidence: {mapping['confidence']}\")\n    \n    return mappings\n\n# Usage\nmappings = generate_mappings_from_csv('source_data.csv')\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"via-api-gateway-recommended",children:"Via API Gateway (Recommended)"}),"\n",(0,s.jsx)(n.p,{children:"The API Gateway provides orchestrated workflows that combine multiple services."}),"\n",(0,s.jsx)(n.h3,{id:"full-transformation-pipeline",children:"Full Transformation Pipeline"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import requests\n\ndef full_transformation_pipeline(csv_file_path):\n    \"\"\"\n    Complete end-to-end transformation:\n    CSV \u2192 Parse \u2192 Map \u2192 Transform \u2192 Sanitize\n    \"\"\"\n    with open(csv_file_path, 'rb') as f:\n        response = requests.post(\n            'http://localhost:3000/api/v1/transform-pipeline',\n            files={'file': f},\n            data={'targetSchema': 'ISO20022_pain.001.001.09'}\n        )\n    \n    result = response.json()\n    \n    if result['success']:\n        print(f\"\u2713 Pipeline completed in {result['processingTime']}\")\n        print(f\"  Source: {result['data']['source']['rowCount']} rows\")\n        print(f\"  Mappings: {len(result['data']['mappings'])}\")\n        print(f\"  XML length: {len(result['data']['xml'])} chars\")\n        \n        return result['data']\n    else:\n        print(f\"\u2717 Pipeline failed: {result['error']['message']}\")\n        return None\n\n# Usage\nresult = full_transformation_pipeline('payments.csv')\n"})}),"\n",(0,s.jsx)(n.h3,{id:"csv-to-xml-only",children:"CSV to XML Only"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import requests\n\ndef csv_to_xml_via_gateway(csv_file_path):\n    \"\"\"Use API Gateway for CSV to XML transformation\"\"\"\n    with open(csv_file_path, 'rb') as f:\n        response = requests.post(\n            'http://localhost:3000/api/v1/csv-to-xml',\n            files={'file': f}\n        )\n    \n    result = response.json()\n    \n    if result['success']:\n        return result['data']['xml']\n    else:\n        raise Exception(result['error']['message'])\n\n# Usage\nxml_output = csv_to_xml_via_gateway('data.csv')\nwith open('output.xml', 'w') as f:\n    f.write(xml_output)\n"})}),"\n",(0,s.jsx)(n.h3,{id:"csv-to-mapping-only",children:"CSV to Mapping Only"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import requests\n\ndef csv_to_mapping_via_gateway(csv_file_path, target_schema):\n    \"\"\"Use API Gateway for CSV to mapping generation\"\"\"\n    with open(csv_file_path, 'rb') as f:\n        response = requests.post(\n            'http://localhost:3000/api/v1/csv-to-mapping',\n            files={'file': f},\n            data={'targetSchema': target_schema}\n        )\n    \n    result = response.json()\n    \n    if result['success']:\n        return result['data']['mappings']\n    else:\n        raise Exception(result['error']['message'])\n\n# Usage\nmappings = csv_to_mapping_via_gateway(\n    'source.csv',\n    'ISO20022_pain.001.001.09'\n)\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"service-to-service-communication",children:"Service-to-Service Communication"}),"\n",(0,s.jsx)(n.h3,{id:"async-integration-with-message-queue",children:"Async Integration with Message Queue"}),"\n",(0,s.jsx)(n.p,{children:"For production environments, use message queues for async processing:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import pika\nimport json\n\ndef publish_csv_for_processing(csv_file_path, queue_name='csv-processing'):\n    \"\"\"Publish CSV to message queue for async processing\"\"\"\n    \n    # Connect to RabbitMQ\n    connection = pika.BlockingConnection(\n        pika.ConnectionParameters('localhost')\n    )\n    channel = connection.channel()\n    \n    # Declare queue\n    channel.queue_declare(queue=queue_name, durable=True)\n    \n    # Read and encode file\n    with open(csv_file_path, 'rb') as f:\n        file_content = f.read()\n    \n    # Publish message\n    message = {\n        'file_name': csv_file_path,\n        'file_content': file_content.decode('latin-1'),  # or base64\n        'target_format': 'ISO20022_pain.001.001.09'\n    }\n    \n    channel.basic_publish(\n        exchange='',\n        routing_key=queue_name,\n        body=json.dumps(message),\n        properties=pika.BasicProperties(\n            delivery_mode=2,  # Make message persistent\n        )\n    )\n    \n    print(f\"Published {csv_file_path} to queue\")\n    connection.close()\n\n# Usage\npublish_csv_for_processing('large_dataset.csv')\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"docker-integration",children:"Docker Integration"}),"\n",(0,s.jsx)(n.h3,{id:"docker-compose-network",children:"Docker Compose Network"}),"\n",(0,s.jsx)(n.p,{children:"All services communicate via Docker network:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:"version: '3.8'\n\nservices:\n  csv-parser:\n    image: csv-parser:latest\n    networks:\n      - fintech-network\n  \n  xml-sanitizer:\n    image: xml-sanitizer:latest\n    networks:\n      - fintech-network\n  \n  mapping-generator:\n    image: mapping-generator:latest\n    networks:\n      - fintech-network\n\nnetworks:\n  fintech-network:\n    driver: bridge\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Access services from within containers:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Instead of localhost, use service names\nCSV_PARSER_URL = 'http://csv-parser:8000'\nXML_SANITIZER_URL = 'http://xml-sanitizer:8080'\nMAPPING_GENERATOR_URL = 'http://mapping-generator:8081'\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"error-handling--retry-logic",children:"Error Handling & Retry Logic"}),"\n",(0,s.jsx)(n.h3,{id:"resilient-integration",children:"Resilient Integration"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import requests\nimport time\nfrom typing import Optional\n\ndef call_service_with_retry(\n    url: str,\n    max_retries: int = 3,\n    backoff_factor: float = 2.0,\n    **kwargs\n) -> Optional[requests.Response]:\n    """\n    Call a service with exponential backoff retry\n    """\n    for attempt in range(max_retries):\n        try:\n            response = requests.post(url, timeout=30, **kwargs)\n            response.raise_for_status()\n            return response\n            \n        except requests.exceptions.RequestException as e:\n            if attempt == max_retries - 1:\n                print(f"Failed after {max_retries} attempts: {e}")\n                return None\n            \n            wait_time = backoff_factor ** attempt\n            print(f"Attempt {attempt + 1} failed, retrying in {wait_time}s...")\n            time.sleep(wait_time)\n    \n    return None\n\n# Usage\nwith open(\'data.csv\', \'rb\') as f:\n    response = call_service_with_retry(\n        \'http://localhost:8000/api/csv/parse\',\n        files={\'file\': f},\n        max_retries=3\n    )\n\nif response:\n    result = response.json()\n    print(f"Success: {result[\'row_count\']} rows")\nelse:\n    print("Failed to process CSV")\n'})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"monitoring--observability",children:"Monitoring & Observability"}),"\n",(0,s.jsx)(n.h3,{id:"request-tracking",children:"Request Tracking"}),"\n",(0,s.jsx)(n.p,{children:"Track requests across services:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import requests\nimport uuid\n\ndef tracked_request(csv_file_path):\n    \"\"\"Make a request with correlation ID for tracking\"\"\"\n    \n    # Generate correlation ID\n    correlation_id = str(uuid.uuid4())\n    \n    headers = {\n        'X-Request-ID': correlation_id,\n        'X-User-ID': 'user-123'\n    }\n    \n    print(f\"Request ID: {correlation_id}\")\n    \n    # Parse CSV\n    with open(csv_file_path, 'rb') as f:\n        parse_response = requests.post(\n            'http://localhost:8000/api/csv/parse',\n            files={'file': f},\n            headers=headers\n        )\n    \n    # Check response headers\n    response_id = parse_response.headers.get('X-Request-ID')\n    print(f\"Response ID: {response_id}\")\n    \n    return parse_response.json()\n\n# Usage - trace this request through all services\nresult = tracked_request('data.csv')\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"security-considerations",children:"Security Considerations"}),"\n",(0,s.jsx)(n.h3,{id:"api-authentication",children:"API Authentication"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import requests\n\ndef authenticated_request(csv_file_path, api_key):\n    \"\"\"Make authenticated request to CSV Parser\"\"\"\n    \n    headers = {\n        'Authorization': f'Bearer {api_key}',\n        'X-API-Key': api_key\n    }\n    \n    with open(csv_file_path, 'rb') as f:\n        response = requests.post(\n            'http://localhost:8000/api/csv/parse',\n            files={'file': f},\n            headers=headers\n        )\n    \n    response.raise_for_status()\n    return response.json()\n\n# Usage\nAPI_KEY = 'your-api-key-here'\nresult = authenticated_request('secure_data.csv', API_KEY)\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,s.jsx)(n.h3,{id:"parallel-processing",children:"Parallel Processing"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import concurrent.futures\nimport requests\n\ndef process_csv_file(file_path):\n    """Process a single CSV file"""\n    with open(file_path, \'rb\') as f:\n        response = requests.post(\n            \'http://localhost:8000/api/csv/parse\',\n            files={\'file\': f}\n        )\n    return file_path, response.json()\n\ndef process_multiple_csvs(file_paths, max_workers=5):\n    """Process multiple CSV files in parallel"""\n    \n    results = {}\n    \n    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n        future_to_file = {\n            executor.submit(process_csv_file, fp): fp \n            for fp in file_paths\n        }\n        \n        for future in concurrent.futures.as_completed(future_to_file):\n            file_path = future_to_file[future]\n            try:\n                file_path, result = future.result()\n                results[file_path] = result\n                print(f"\u2713 Processed {file_path}")\n            except Exception as e:\n                print(f"\u2717 Failed {file_path}: {e}")\n                results[file_path] = None\n    \n    return results\n\n# Usage\nfiles = [\'file1.csv\', \'file2.csv\', \'file3.csv\', \'file4.csv\']\nresults = process_multiple_csvs(files)\n'})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Review the ",(0,s.jsx)(n.a,{href:"/fintech-mapping-features/intelligentmappingpoc/docs/guides/integration-overview",children:"Integration Overview"})," for complete integration patterns"]}),"\n",(0,s.jsx)(n.li,{children:"Check the API Gateway documentation in the repository"}),"\n",(0,s.jsx)(n.li,{children:"See the docker-compose.yml configuration in the repository root"}),"\n",(0,s.jsxs)(n.li,{children:["See ",(0,s.jsx)(n.a,{href:"/fintech-mapping-features/intelligentmappingpoc/docs/csv-parser/examples",children:"Examples"})," for more code samples"]}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(p,{...e})}):p(e)}},28453:(e,n,r)=>{r.d(n,{R:()=>a,x:()=>o});var t=r(96540);const s={},i=t.createContext(s);function a(e){const n=t.useContext(i);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);